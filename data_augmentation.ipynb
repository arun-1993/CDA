{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from operator import itemgetter\n",
    "from itertools import groupby\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_timestamp(date_string):#convert time string to float value\n",
    "    time_stamp = time.strptime(date_string, '%Y-%m-%d %H:%M:%S')\n",
    "    return time.mktime(time_stamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(before_aggregate, aggregate_feature):\n",
    "    if aggregate_feature == 'day':\n",
    "        after_aggregate = []\n",
    "        pos_date = -1\n",
    "        before_aggregate.sort(key = itemgetter(9))#sort by timestamp\n",
    "        temp = groupby(before_aggregate, itemgetter(-2))\n",
    "        group_unit = []\n",
    "        mean = []\n",
    "        for i, item in temp:# i is group id\n",
    "            for jtem in item:# unit in each group\n",
    "                group_unit.append(jtem)\n",
    "            #for feature_i in xrange(6):\n",
    "            #    mean.append(zip(group_unit)[feature_i])\n",
    "            #after_aggregate.append(group_unit)\n",
    "            after_aggregate.append(mean)\n",
    "            group_unit = []\n",
    "        #print after_aggregate[0]\n",
    "        #print before_aggregate[0]\n",
    "    if aggregate_feature == 'client':\n",
    "        after_aggregate = []\n",
    "        pos_client = -3\n",
    "        before_aggregate.sort(key = itemgetter(pos_client))#sort with cardID firstly，if sort with 2 feature, itemgetter(num1,num2)\n",
    "        temp = groupby(before_aggregate, itemgetter(pos_client))#group\n",
    "        group_unit = []\n",
    "        for i, item in temp:# i is group id\n",
    "            for jtem in item:# unit in each group\n",
    "                group_unit.append(jtem)\n",
    "            after_aggregate.append(group_unit)\n",
    "            group_unit = []\n",
    "    return after_aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_mean(before_aggregate):\n",
    "    #print before_aggregate[0]\n",
    "    if True:\n",
    "        after_aggregate = []\n",
    "        pos_date = -1\n",
    "        before_aggregate.sort(key = itemgetter(-1))#sort by timestamp\n",
    "        temp = groupby(before_aggregate, itemgetter(-1))\n",
    "        group_unit = []\n",
    "        mean = []\n",
    "        for i, item in temp:# i is group id\n",
    "            for jtem in item:# unit in each group\n",
    "                group_unit.append(list(jtem))\n",
    "            #print group_unit\n",
    "            if len(zip(group_unit)) < 2:\n",
    "                after_aggregate.append(group_unit)\n",
    "                group_unit = []\n",
    "            if len(zip(group_unit)) >= 2:\n",
    "                #print zip(group_unit)\n",
    "                for feature_i in range(14):\n",
    "                    #print zip(group_unit)[feature_i]\n",
    "                    mean.append(sum(zip(*group_unit)[feature_i])/len(zip(group_unit)))\n",
    "                after_aggregate.append(mean)\n",
    "                group_unit = []\n",
    "                mean = []\n",
    "        #print after_aggregate[0]\n",
    "        #print before_aggregate[0]\n",
    "    return after_aggregate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    src = 'data_for_student_case.csv'\n",
    "    ah = open(src, 'r')\n",
    "    x = []#contains features\n",
    "    y = []#contains labels\n",
    "    data = []\n",
    "    color = []\n",
    "    (issuercountry_set, txvariantcode_set, currencycode_set, shoppercountry_set, interaction_set,\n",
    "    verification_set, accountcode_set, mail_id_set, ip_id_set, card_id_set) = [set() for _ in range(10)]\n",
    "    (issuercountry_dict, txvariantcode_dict, currencycode_dict, shoppercountry_dict, interaction_dict,\n",
    "    verification_dict, accountcode_dict, mail_id_dict, ip_id_dict, card_id_dict) = [{} for _ in range(10)]\n",
    "    #label_set\n",
    "    #cvcresponse_set = set()\n",
    "    ah.readline()#skip first line\n",
    "    for line_ah in ah:\n",
    "        if line_ah.strip().split(',')[9]=='Refused':# remove the row with 'refused' label, since it's uncertain about fraud\n",
    "            continue\n",
    "        if 'na' in str(line_ah.strip().split(',')[14]).lower() or 'na' in str(line_ah.strip().split(',')[4].lower()):\n",
    "            continue\n",
    "        bookingdate = string_to_timestamp(line_ah.strip().split(',')[1])# date reported flaud\n",
    "        issuercountry = line_ah.strip().split(',')[2]#country code\n",
    "        issuercountry_set.add(issuercountry)\n",
    "        txvariantcode = line_ah.strip().split(',')[3]#type of card: visa/master\n",
    "        txvariantcode_set.add(txvariantcode)\n",
    "        issuer_id = float(line_ah.strip().split(',')[4])#bin card issuer identifier\n",
    "        amount = float(line_ah.strip().split(',')[5])#transaction amount in minor units\n",
    "        currencycode = line_ah.strip().split(',')[6]\n",
    "        currencycode_set.add(currencycode)\n",
    "        shoppercountry = line_ah.strip().split(',')[7]#country code\n",
    "        shoppercountry_set.add(shoppercountry)\n",
    "        interaction = line_ah.strip().split(',')[8]#online transaction or subscription\n",
    "        interaction_set.add(interaction)\n",
    "        if line_ah.strip().split(',')[9] == 'Chargeback':\n",
    "            label = 1#label fraud\n",
    "        else:\n",
    "            label = 0#label save\n",
    "        verification = line_ah.strip().split(',')[10]#shopper provide CVC code or not\n",
    "        verification_set.add(verification)\n",
    "        cvcresponse = line_ah.strip().split(',')[11]#0 = Unknown, 1=Match, 2=No Match, 3-6=Not checked\n",
    "        if int(cvcresponse) > 2:\n",
    "            cvcresponse = 3\n",
    "        year_info = datetime.datetime.strptime(line_ah.strip().split(',')[12],'%Y-%m-%d %H:%M:%S').year\n",
    "        month_info = datetime.datetime.strptime(line_ah.strip().split(',')[12],'%Y-%m-%d %H:%M:%S').month\n",
    "        day_info = datetime.datetime.strptime(line_ah.strip().split(',')[12],'%Y-%m-%d %H:%M:%S').day\n",
    "        creationdate = str(year_info)+'-'+str(month_info)+'-'+str(day_info)#Date of transaction\n",
    "        creationdate_stamp = string_to_timestamp(line_ah.strip().split(',')[12])#Date of transaction-time stamp\n",
    "        accountcode = line_ah.strip().split(',')[13]#merchant’s webshop\n",
    "        accountcode_set.add(accountcode)\n",
    "        mail_id = int(float(line_ah.strip().split(',')[14].replace('email','')))#mail\n",
    "        mail_id_set.add(mail_id)\n",
    "        ip_id = int(float(line_ah.strip().split(',')[15].replace('ip','')))#ip\n",
    "        ip_id_set.add(ip_id)\n",
    "        card_id = int(float(line_ah.strip().split(',')[16].replace('card','')))#card\n",
    "        card_id_set.add(card_id)\n",
    "        data.append([issuercountry, txvariantcode, issuer_id, amount, currencycode,\n",
    "                    shoppercountry, interaction, verification, cvcresponse, creationdate_stamp,\n",
    "                     accountcode, mail_id, ip_id, card_id, label, creationdate])# add the interested features here\n",
    "        #y.append(label)# add the labels\n",
    "    # print(data)\n",
    "    data = sorted(data, key = lambda k: k[-1])\n",
    "    day_aggregate = aggregate(data,'day')\n",
    "    client_aggregate = aggregate(data,'client')\n",
    "    transaction_num_day = []\n",
    "    for item in day_aggregate:\n",
    "        transaction_num_day.append(len(item))\n",
    "#     plt.figure(1)\n",
    "#     plt.plot(transaction_num_day, color = 'c', linewidth = 2)\n",
    "#     plt.plot()\n",
    "#     plt.text(2,0.0,'Date: 2015-10-8')\n",
    "#     plt.xlabel('Date')\n",
    "#     plt.ylabel('Number of Transactions')\n",
    "#     plt.xlim([0,125])\n",
    "#     plt.axis('tight')\n",
    "#     plt.savefig('Day Aggregating.png')\n",
    "#     transaction_num_client = []\n",
    "#     for item in client_aggregate:\n",
    "#         transaction_num_client.append(len(item))\n",
    "#     plt.figure(2)\n",
    "#     plt.plot(transaction_num_client, color = 'c', linewidth = 2)\n",
    "#     #plt.text(99,9668,'Date: 2015-10-8')\n",
    "#     plt.xlabel('Client ID')\n",
    "#     plt.ylabel('Number of Transactions')\n",
    "#     plt.axis('tight')\n",
    "#     plt.savefig('Client Aggregating.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210542\n"
     ]
    }
   ],
   "source": [
    "for item in data:#split data into x,y\n",
    "    x.append(item[0:-2])\n",
    "    y.append(item[-2])\n",
    "'''map number to each categorial feature'''\n",
    "for item in list(issuercountry_set):\n",
    "    issuercountry_dict[item] = list(issuercountry_set).index(item)\n",
    "for item in list(txvariantcode_set):\n",
    "    txvariantcode_dict[item] = list(txvariantcode_set).index(item)\n",
    "for item in list(currencycode_set):\n",
    "    currencycode_dict[item] = list(currencycode_set).index(item)\n",
    "for item in list(shoppercountry_set):\n",
    "    shoppercountry_dict[item] = list(shoppercountry_set).index(item)\n",
    "for item in list(interaction_set):\n",
    "    interaction_dict[item] = list(interaction_set).index(item)\n",
    "for item in list(verification_set):\n",
    "    verification_dict[item] = list(verification_set).index(item)\n",
    "for item in list(accountcode_set):\n",
    "    accountcode_dict[item] = list(accountcode_set).index(item)\n",
    "print(len(list(card_id_set)))\n",
    "#for item in list(card_id_set):\n",
    "#    card_id_dict[item] = list(card_id_set).index(item)\n",
    "'''modify categorial feature to number in data set'''\n",
    "for item in x:\n",
    "    item[0] = issuercountry_dict[item[0]]\n",
    "    item[1] = txvariantcode_dict[item[1]]\n",
    "    item[4] = currencycode_dict[item[4]]\n",
    "    item[5] = shoppercountry_dict[item[5]]\n",
    "    item[6] = interaction_dict[item[6]]\n",
    "    item[7] = verification_dict[item[7]]\n",
    "    item[10] = accountcode_dict[item[10]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_mean = []\n",
    "#x_mean = aggregate_mean(x);\n",
    "x_mean = x;\n",
    "des = 'original_data.csv'\n",
    "des1 = 'aggregate_data.csv'\n",
    "ch_dfa = open(des,'w')\n",
    "#ch_dfa.write('txid,bookingdate,issuercountrycode,txvariantcode,bin,amount,'+\n",
    "#             'currencycode,shoppercountrycode,shopperinteraction,simple_journal,'+\n",
    " #            'cardverificationcodesupplied,cvcresponsecode,creationdate,accountcode,mail_id,ip_id,card_id')\n",
    "#ch_dfa.write('\\n')\n",
    "sentence = []\n",
    "for i in range(len(x_mean)):\n",
    "    for j in range(len(x_mean[i])):\n",
    "        sentence.append(str(x_mean[i][j]))\n",
    "    sentence.append(str(y[i]))\n",
    "    ch_dfa.write(' '.join(sentence))\n",
    "    ch_dfa.write('\\n')\n",
    "    sentence=[]\n",
    "    ch_dfa.flush()    \n",
    "TP, FP, FN, TN = 0, 0, 0, 0\n",
    "x_array = np.array(x)\n",
    "y_array = np.array(y)\n",
    "usx = x_array\n",
    "usy = y_array\n",
    "usx = usx.astype(np.float64)\n",
    "usy = usy.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function _ratio_float is deprecated; Use a float for 'ratio' is deprecated from version 0.2. The support will be removed in 0.4. Use a dict, str, or a callable instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(usx, usy, test_size = 0.2)#test_size: proportion of train/test data\n",
    "\n",
    "# count = 0\n",
    "# count_negative\n",
    "# for i in y_train:\n",
    "#     if i >0:\n",
    "#         count += 1\n",
    "#     else:\n",
    "#         count_negative += 1\n",
    "# print(count)\n",
    "\n",
    "## >>>Data Augmentation!<<<(SMOTE)\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 1.0)\n",
    "x_res, y_res = sm.fit_sample(x_train, y_train)\n",
    "\n",
    "\n",
    "# count_res = 0\n",
    "# count_res_negative = 0\n",
    "# for i in y_res:\n",
    "#     if i >0:\n",
    "#         count_res += 1\n",
    "#     else:\n",
    "#         count_res_negative += 1\n",
    "                    \n",
    "# print(count_res)\n",
    "# print(count_res_negative)\n",
    "# print(len(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 13\n",
      "FP: 871\n",
      "FN: 45\n",
      "TN: 46411\n"
     ]
    }
   ],
   "source": [
    "## >>>Classification!<<<(KNN)\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier(algorithm = 'kd_tree')\n",
    "clf.fit(x_res, y_res)\n",
    "y_predict = clf.predict(x_test)\n",
    "\n",
    "for i in range(len(y_predict)):\n",
    "    if y_test[i]==1 and y_predict[i]==1:\n",
    "        TP += 1\n",
    "    if y_test[i]==0 and y_predict[i]==1:\n",
    "        FP += 1\n",
    "    if y_test[i]==1 and y_predict[i]==0:\n",
    "        FN += 1\n",
    "    if y_test[i]==0 and y_predict[i]==0:\n",
    "        TN += 1\n",
    "print('TP: '+ str(TP))\n",
    "print('FP: '+ str(FP))\n",
    "print('FN: '+ str(FN))\n",
    "print('TN: '+ str(TN))\n",
    "#print confusion_matrix(y_test, answear) watch out the element in confusion matrix\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_predict)\n",
    "predict_proba = clf.predict_proba(x_test)#the probability of each smple labelled to positive or negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22413793103448276\n"
     ]
    }
   ],
   "source": [
    "recall = TP/(TP+FN)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
